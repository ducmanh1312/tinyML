{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icnlab/anaconda3/envs/aiot/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# include\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from pathlib import Path\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "from PDDD.Codes.modelpy.visual_model.ResNet_50_101_152 import ResNet152\n",
    "from PDDD.Codes.modelpy.visual_model.ViT_L import VisionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config \n",
    "# ----------------------------\n",
    "BATCH_SIZE = 60\n",
    "# NUM_CLASSES = 27\n",
    "BASE_LR = 0.003\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_EPOCHS = 2 # Trong 2 epoch đầu, learning rate sẽ được tăng dần từ nhỏ đến BASE_LR\n",
    "EPOCHS = 100\n",
    "LAYER_DECAY = 0.8\n",
    "ACCUM_GRAD_STEPS = 1 # Gradient accumulation: để mô phỏng batch size lớn hơn.\n",
    "DATA_DIR = \"/media/icnlab/Data/Manh/tinyML/FieldPlant-11/cropped\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataModule\n",
    "# ----------------------------\n",
    "class FilteredImageFolder(ImageFolder):\n",
    "    def __init__(self, root, included_classes, **kwargs):\n",
    "        super().__init__(root, **kwargs)\n",
    "        # Lưu lại các chỉ số class cần giữ\n",
    "        included_indices = [self.class_to_idx[cls] for cls in included_classes]\n",
    "        self.samples = [s for s in self.samples if s[1] in included_indices]\n",
    "        self.targets = [s[1] for s in self.samples]\n",
    "\n",
    "\n",
    "class Dataset(pl.LightningDataModule):\n",
    "    # init dataset, split, transform, dataloader\n",
    "    def __init__(self, data_dir, batch_size, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "        super().__init__()\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Define separate transforms for training (with augmentation) and evaluation\n",
    "        self.train_transform = T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.RandomHorizontalFlip(p=0.5),  # Randomly flip images horizontally\n",
    "            T.RandomRotation(degrees=15),    # Randomly rotate images by up to 15 degrees\n",
    "            T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # Random color adjustments\n",
    "            T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random translations\n",
    "            T.RandomPerspective(distortion_scale=0.2, p=0.5),  # Random perspective changes\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "        ])\n",
    "        \n",
    "        # Transform for validation and testing (no augmentation)\n",
    "        self.eval_transform = T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.416, 0.468, 0.355],   # normalize\n",
    "                                std=[0.210, 0.206, 0.213])\n",
    "        ])  # in PDDD paper\n",
    "        \n",
    "        # Ensure ratios sum to 1\n",
    "        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-5, \"Ratios must sum to 1\"\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.test_ratio = test_ratio\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Load the full dataset with eval transform initially\n",
    "        self.full_dataset = ImageFolder(self.data_dir, transform=self.eval_transform)\n",
    "\n",
    "        # bug\n",
    "        # included = ['Tomato Brown Spots', 'Tomato blight leaf', 'Tomato healthy', 'Tomato leaf yellow virus']\n",
    "        # self.full_dataset = FilteredImageFolder(self.data_dir, included, transform=self.eval_transform)\n",
    "        \n",
    "    # Calculate split sizes\n",
    "        dataset_size = len(self.full_dataset)\n",
    "        train_size = int(dataset_size * self.train_ratio)\n",
    "        val_size = int(dataset_size * self.val_ratio)\n",
    "        test_size = dataset_size - train_size - val_size\n",
    "        \n",
    "        # Split the dataset\n",
    "        from torch.utils.data import random_split\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = random_split(\n",
    "            self.full_dataset,\n",
    "            [train_size, val_size, test_size],\n",
    "            generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=8)\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer-wise LR decay helper\n",
    "# ----------------------------\n",
    "def get_layer_decay_param_groups(model, base_lr, weight_decay, layer_decay):\n",
    "    param_groups = []\n",
    "    layers = list(model.named_parameters())\n",
    "    num_layers = len(layers)\n",
    "\n",
    "    for i, (name, param) in enumerate(layers):\n",
    "        if not param.requires_grad:\n",
    "            continue\n",
    "        lr = base_lr * (layer_decay ** (num_layers - i - 1))\n",
    "        param_groups.append({\n",
    "            \"params\": [param],\n",
    "            \"lr\": lr,\n",
    "            \"weight_decay\": weight_decay if param.ndim >= 2 else 0.0\n",
    "        })\n",
    "    return param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightning Module\n",
    "# ----------------------------\n",
    "class EVA02Lightning(pl.LightningModule):\n",
    "    def __init__(self, embedding_dim=2048, projection_dim=128):\n",
    "        super().__init__()\n",
    "        # Load the base model\n",
    "        model = ResNet152()\n",
    "        model_path = \"/media/icnlab/Data/Manh/tinyML/PDDD/model/ResNet152.std\"\n",
    "        model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if name.startswith(('conv1', 'layer1', 'layer2', 'layer3')):\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "        \n",
    "    # Add a projection head for contrastive learning\n",
    "        self.backbone = nn.Sequential(*list(model.children())[:-1])  # Remove final classification layer\n",
    "        \n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, projection_dim)\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            self.backbone = torch.compile(self.backbone)\n",
    "        except Exception:\n",
    "            pass  # torch.compile requires PyTorch 2+\n",
    "\n",
    "        # Define contrastive loss\n",
    "        self.loss_fn = losses.SupConLoss(temperature=0.07)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get embeddings from backbone\n",
    "        features = self.backbone(x)\n",
    "        # Handle potential dimension issues\n",
    "        if len(features.shape) > 2:\n",
    "            features = features.squeeze()\n",
    "        # Get projected embeddings\n",
    "        projections = self.projection_head(features)\n",
    "        # Normalize projections for contrastive loss\n",
    "        normalized_projections = nn.functional.normalize(projections, dim=1)\n",
    "        return features, normalized_projections\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        # Get embeddings and normalized projections\n",
    "        _, normalized_projections = self(x)\n",
    "        \n",
    "        # Calculate contrastive loss\n",
    "        loss = self.loss_fn(normalized_projections, y)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        # For validation, we'll just log the contrastive loss\n",
    "        _, normalized_projections = self(x)\n",
    "        val_loss = self.loss_fn(normalized_projections, y)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "        \n",
    "        # Since we don't have a classifier, we can't calculate accuracy directly\n",
    "        # We could implement a nearest-neighbor evaluation here if needed\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Get parameters with layer-wise decay for backbone\n",
    "        param_groups = get_layer_decay_param_groups(self.backbone, BASE_LR, WEIGHT_DECAY, LAYER_DECAY)\n",
    "        \n",
    "        # Add projection head parameters\n",
    "        param_groups.append({\n",
    "            \"params\": self.projection_head.parameters(), \n",
    "            \"lr\": BASE_LR, \n",
    "            \"weight_decay\": WEIGHT_DECAY\n",
    "        })\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(param_groups, eps=1e-6)\n",
    "\n",
    "        def lr_schedule_fn(current_step):\n",
    "            if current_step < WARMUP_EPOCHS:\n",
    "                return float(current_step) / float(max(1, WARMUP_EPOCHS))\n",
    "            else:\n",
    "                progress = float(current_step - WARMUP_EPOCHS) / float(max(1, EPOCHS - WARMUP_EPOCHS))\n",
    "                return max(0.0, 0.5 * (1.0 + torch.cos(torch.tensor(progress * 3.1415926535))))\n",
    "\n",
    "        scheduler = {\n",
    "            \"scheduler\": LambdaLR(optimizer, lr_lambda=lr_schedule_fn),\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "        }\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2025-05-29 01:41:37.152984: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748457697.165490  282514 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748457697.169352  282514 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748457697.179325  282514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748457697.179348  282514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748457697.179349  282514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748457697.179351  282514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-29 01:41:37.182813: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/icnlab/anaconda3/envs/aiot/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /media/icnlab/Data/Manh/tinyML/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type            | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | backbone        | OptimizedModule | 58.1 M | train\n",
      "1 | projection_head | Sequential      | 1.1 M  | train\n",
      "2 | loss_fn         | SupConLoss      | 0      | train\n",
      "------------------------------------------------------------\n",
      "16.1 M    Trainable params\n",
      "43.2 M    Non-trainable params\n",
      "59.3 M    Total params\n",
      "237.034   Total estimated model params size (MB)\n",
      "581       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at: 2025-05-29 01:42:04                                   \n",
      "Epoch 0: 100%|██████████| 33/33 [01:58<00:00,  0.28it/s, v_num=18, val_loss=4.230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 4.230\n",
      "Epoch 0, global step 33: 'val_loss' reached 4.22982 (best 4.22982), saving model to '/media/icnlab/Data/Manh/tinyML/checkpoints/eva02-00-4.23-0.00.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 33/33 [00:09<00:00,  3.47it/s, v_num=18, val_loss=3.760]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.468 >= min_delta = 0.0. New best score: 3.762\n",
      "Epoch 1, global step 66: 'val_loss' reached 3.76182 (best 3.76182), saving model to '/media/icnlab/Data/Manh/tinyML/checkpoints/eva02-01-3.76-0.00.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 33/33 [00:09<00:00,  3.49it/s, v_num=18, val_loss=3.760]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 3.757\n",
      "Epoch 2, global step 99: 'val_loss' reached 3.75687 (best 3.75687), saving model to '/media/icnlab/Data/Manh/tinyML/checkpoints/eva02-02-3.76-0.00.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 33/33 [00:09<00:00,  3.47it/s, v_num=18, val_loss=3.740]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.021 >= min_delta = 0.0. New best score: 3.736\n",
      "Epoch 3, global step 132: 'val_loss' reached 3.73562 (best 3.73562), saving model to '/media/icnlab/Data/Manh/tinyML/checkpoints/eva02-03-3.74-0.00.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s, v_num=18, val_loss=3.720]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 3.717\n",
      "Epoch 4, global step 165: 'val_loss' reached 3.71676 (best 3.71676), saving model to '/media/icnlab/Data/Manh/tinyML/checkpoints/eva02-04-3.72-0.00.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 33/33 [00:09<00:00,  3.38it/s, v_num=18, val_loss=3.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 198: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 33/33 [00:09<00:00,  3.38it/s, v_num=18, val_loss=3.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 231: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 33/33 [00:09<00:00,  3.34it/s, v_num=18, val_loss=3.830]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 264: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 33/33 [00:10<00:00,  3.29it/s, v_num=18, val_loss=3.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 297: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 33/33 [00:10<00:00,  3.27it/s, v_num=18, val_loss=4.040]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 3.717. Signaling Trainer to stop.\n",
      "Epoch 9, global step 330: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 33/33 [00:12<00:00,  2.58it/s, v_num=18, val_loss=4.040]\n",
      "Best model checkpoint: /media/icnlab/Data/Manh/tinyML/checkpoints/eva02-04-3.72-0.00.ckpt\n",
      "Best model score: 3.7168\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    from datetime import timedelta\n",
    "    import os\n",
    "    \n",
    "    # Create checkpoints directory if it doesn't exist\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    \n",
    "    pl.seed_everything(42)\n",
    "    data = Dataset(DATA_DIR, BATCH_SIZE)\n",
    "    model = EVA02Lightning()\n",
    "    \n",
    "    # Define checkpoint callback\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=\"checkpoints\",\n",
    "        filename=\"eva02-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,  # Save the 1 best models\n",
    "        save_last=True,  # Additionally save the last model\n",
    "        verbose=True,\n",
    "        auto_insert_metric_name=False\n",
    "    )\n",
    "    \n",
    "    # Add early stopping callback (optional)\n",
    "    early_stop_callback = pl.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,  # Stop if no improvement for 5 epochs\n",
    "        mode=\"min\",\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Add timer callback to track training time\n",
    "    class TimingCallback(pl.Callback):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.epoch_start_time = None\n",
    "            self.training_start_time = None\n",
    "            self.epoch_times = []\n",
    "        \n",
    "        def on_train_start(self, trainer, pl_module):\n",
    "            self.training_start_time = time.time()\n",
    "            print(f\"Training started at: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        def on_train_epoch_start(self, trainer, pl_module):\n",
    "            self.epoch_start_time = time.time()\n",
    "            if trainer.current_epoch > 0 and len(self.epoch_times) > 0:\n",
    "                avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)\n",
    "                remaining_epochs = trainer.max_epochs - trainer.current_epoch\n",
    "                est_remaining_time = avg_epoch_time * remaining_epochs\n",
    "                print(f\"Estimated time remaining: {timedelta(seconds=int(est_remaining_time))}\")\n",
    "        \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_time = epoch_end_time - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "\n",
    "        print(f\"Epoch {trainer.current_epoch} completed in: {timedelta(seconds=int(epoch_time))}\")\n",
    "\n",
    "        if len(self.epoch_times) > 0:\n",
    "            avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)\n",
    "            remaining_epochs = trainer.max_epochs - trainer.current_epoch - 1\n",
    "            est_remaining_time = avg_epoch_time * remaining_epochs\n",
    "\n",
    "            print(f\"Average epoch time: {timedelta(seconds=int(avg_epoch_time))}\")\n",
    "            print(f\"Estimated time remaining: {timedelta(seconds=int(est_remaining_time))}\")\n",
    "        \n",
    "        def on_train_end(self, trainer, pl_module):\n",
    "            total_time = time.time() - self.training_start_time\n",
    "            print(f\"\\nTraining completed in: {timedelta(seconds=int(total_time))}\")\n",
    "            print(f\"Finished at: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Create the timing callback\n",
    "    timing_callback = TimingCallback()\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS,\n",
    "        accumulate_grad_batches=ACCUM_GRAD_STEPS,\n",
    "        precision=\"16-mixed\",\n",
    "        gradient_clip_val=1.0,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=\"auto\",  # multi-GPU nếu có\n",
    "        # strategy=\"ddp_find_unused_parameters_false\", \n",
    "        log_every_n_steps=10,\n",
    "        callbacks=[checkpoint_callback, early_stop_callback, timing_callback],  # Add callbacks here\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=data, \n",
    "    # ckpt_path='/media/icnlab/Data/Manh/tinyML/checkpoints/eva02-07-2.61-0.00.ckpt'\n",
    "    )\n",
    "    \n",
    "    # Print path to best model checkpoint\n",
    "    print(f\"Best model checkpoint: {checkpoint_callback.best_model_path}\")\n",
    "    print(f\"Best model score: {checkpoint_callback.best_model_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = EVA02Lightning.load_from_checkpoint(checkpoint_callback.best_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
