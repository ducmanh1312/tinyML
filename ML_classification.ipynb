{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778, 778)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r cluster_labels cluster_embeddings\n",
    "len(cluster_labels), len(cluster_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def split_input(X, y, test_size=0.2, random_state=42, stratify=None):\n",
    "    \"\"\"\n",
    "    Chia dữ liệu X, y thành train/test.\n",
    "    - stratify: nếu muốn giữ tỉ lệ nhãn (ví dụ stratify=y)\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=stratify\n",
    "    )\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def encode_labels(labels):\n",
    "    \"\"\"\n",
    "    Encode nhãn từ chuỗi/kiểu bất kỳ sang số nguyên.\n",
    "    \"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(labels)\n",
    "    return encoded_labels, encoder\n",
    "\n",
    "def decode_labels(encoded_labels, encoder):\n",
    "    \"\"\"\n",
    "    Chuyển nhãn số về lại nhãn gốc dùng encoder.\n",
    "    \"\"\"\n",
    "    return encoder.inverse_transform(encoded_labels)\n",
    "\n",
    "encoded_labels, label_encoder = encode_labels(cluster_labels)\n",
    "\n",
    "# 2. Tách train/test\n",
    "X_train, y_train, X_test, y_test = split_input(\n",
    "    cluster_embeddings,\n",
    "    encoded_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=encoded_labels  # giữ tỉ lệ nhãn\n",
    ")\n",
    "\n",
    "# 3. Khi cần decode lại nhãn số thành nhãn gốc\n",
    "y_train_decoded = decode_labels(y_train, label_encoder)\n",
    "y_test_decoded = decode_labels(y_test, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "def train(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_scores = accuracy_score(y_test, y_pred)\n",
    "    print(model.__class__.__name__)\n",
    "    print('Accuracy: ', acc_scores, end='  ')\n",
    "    print('Precision: ', precision_score(y_test, y_pred, average='weighted'))\n",
    "    print('Recall: ', recall_score(y_test, y_pred, average='weighted'), end='  ')\n",
    "    print('F1 Score: ', f1_score(y_test, y_pred, average='weighted'))\n",
    "    return model\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "# class_weight_dict = None\n",
    "\n",
    "models = []\n",
    "\n",
    "# Khởi tạo model hỗ trợ class_weight\n",
    "if class_weight_dict:\n",
    "    models = [\n",
    "        DecisionTreeClassifier(random_state=42, class_weight=class_weight_dict),\n",
    "        RandomForestClassifier(random_state=42, class_weight=class_weight_dict),\n",
    "        LogisticRegression(random_state=42, class_weight=class_weight_dict, max_iter=1000),\n",
    "        SVC(random_state=42, class_weight=class_weight_dict)\n",
    "    ]\n",
    "else:\n",
    "    models = [\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        LogisticRegression(random_state=42, max_iter=1000),\n",
    "        SVC(random_state=42),\n",
    "\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        CatBoostClassifier(verbose=0, random_state=42),\n",
    "        XGBClassifier(random_state=42)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.31944444, 0.52006689, 0.70681818, 2.32089552])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Accuracy:  0.5897435897435898  Precision:  0.610692496853211\n",
      "Recall:  0.5897435897435898  F1 Score:  0.5983013647856188\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy:  0.6730769230769231  Precision:  0.6789940828402367\n",
      "Recall:  0.6730769230769231  F1 Score:  0.674087024087024\n",
      "\n",
      "\n",
      "LogisticRegression\n",
      "Accuracy:  0.6987179487179487  Precision:  0.7543910396426893\n",
      "Recall:  0.6987179487179487  F1 Score:  0.7119653553948425\n",
      "\n",
      "\n",
      "SVC\n",
      "Accuracy:  0.6666666666666666  Precision:  0.7195556016310733\n",
      "Recall:  0.6666666666666666  F1 Score:  0.6761916035353536\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    # Cảnh báo cho model không hỗ trợ class_weight khi đa lớp\n",
    "    if class_weight_dict and not hasattr(model, 'class_weight'):\n",
    "        print(f\"Chú ý: {model.__class__.__name__} không hỗ trợ class_weight trực tiếp.\")\n",
    "    model = train(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier (with oversampling)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "Accuracy:  0.7371794871794872  Precision:  0.7452818202818202\n",
      "Recall:  0.7371794871794872  F1 Score:  0.7404618242495759\n",
      "\n",
      "\n",
      "XGBClassifier (with oversampling)\n",
      "XGBClassifier\n",
      "Accuracy:  0.6538461538461539  Precision:  0.6670774398151901\n",
      "Recall:  0.6538461538461539  F1 Score:  0.6585562549347596\n",
      "\n",
      "\n",
      "CatBoostClassifier (with oversampling)\n",
      "CatBoostClassifier\n",
      "Accuracy:  0.6666666666666666  Precision:  0.6964739337030359\n",
      "Recall:  0.6666666666666666  F1 Score:  0.677119923087665\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def train_with_oversampling(model, X_train, y_train, X_test, y_test):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    print(f'{model.__class__.__name__} (with oversampling)')\n",
    "    return train(model, X_resampled, y_resampled, X_test, y_test)\n",
    "\n",
    "models_without_class_weight = [\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    XGBClassifier(random_state=42),\n",
    "    CatBoostClassifier(verbose=0, random_state=42)\n",
    "]\n",
    "\n",
    "for model in models_without_class_weight:\n",
    "    model = train_with_oversampling(model, X_train, y_train, X_test, y_test)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_sample_weight\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sample_weight = compute_sample_weight(class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m, y=\u001b[43my_train\u001b[49m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(model, X_train, y_train, X_test, y_test):\n\u001b[32m      6\u001b[39m     model.fit(X_train, y_train, sample_weight=sample_weight)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "def train(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n==== {model.__class__.__name__} ====\")\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "    print('Recall:', recall_score(y_test, y_pred, average='macro'))\n",
    "    print('F1 Score:', f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # Decode nhãn về lại chuỗi (nếu cần)\n",
    "    y_pred_labels = le.inverse_transform(y_pred.astype(int))\n",
    "    y_test_labels = le.inverse_transform(y_test)\n",
    "\n",
    "    # Đánh giá\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test_labels, y_pred_labels))\n",
    "\n",
    "    return model\n",
    "\n",
    "models = [\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "]\n",
    "\n",
    "# 6. Train và đánh giá từng model\n",
    "for model in models:\n",
    "    trained_model = train(model,    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 300, step=50),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 5, 50, step=5),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        max_features=trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score\n",
    "\n",
    "# Tạo và tối ưu hóa Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# In kết quả tốt nhất\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "print(\"Best Recall Score:\", study.best_value)\n",
    "\n",
    "# Đánh giá trên bộ tham số tốt nhất\n",
    "best_model_rf = RandomForestClassifier(**study.best_params, random_state=42, n_jobs=-1)\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "y_pred = best_model_rf.predict(X_test)\n",
    "\n",
    "print(\"*\" * 100)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score:', f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "\n",
    "# Save model\n",
    "joblib.dump(best_model_rf, 'best_model_rf.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
